{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_dKfEYYS2Mu"
      },
      "source": [
        "# Parte 1: DCClasficador de sonidos "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nota de los ayudantes: Por motivos de desempeño de las redes neuronales, recomendamos realizar esta tarea en Google Colab."
      ],
      "metadata": {
        "id": "LuRI8d21L3gX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las siguientes tres celdas te permiten descargar el dataset directamente desde Kaggle (una plataforma de inteligencia artificial y ciencia de datos). Esto puede facilitar la descarga, pero siéntete libre de utilizar otros métodos para acceder al set de datos."
      ],
      "metadata": {
        "id": "A40C47ilMCVG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmqXTBxjWIsj"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od"
      ],
      "metadata": {
        "id": "q6-Y9OWGKvj_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# necesitas autenticarte para descargar el dataset directamente desde kaggle\n",
        "# más información en https://www.kaggle.com/docs/api\n",
        "\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/chrisfilo/urbansound8k\"\n",
        ")"
      ],
      "metadata": {
        "id": "xoE_MdQYK6CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z_AirFCS2My"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "import librosa\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2zpL2AJS2M0"
      },
      "outputs": [],
      "source": [
        "# Creamos una semilla para que los resultados sean replicables\n",
        "n_alumno = # tu número de alumno\n",
        "np.random.seed(n_alumno)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_bHzVg_S2M1"
      },
      "outputs": [],
      "source": [
        "# Definimos el path al csv\n",
        "path =  # aquí va la ruta donde almacenaste la carpeta con datos\n",
        "\n",
        "# Importamos el csv\n",
        "meta_data = pd.read_csv(path + \"UrbanSound8K.csv\")\n",
        "\n",
        "# Veamos las primeras 5 observaciones\n",
        "meta_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos una función que convierte el audio en mfcc\n",
        "def features_extract(file):\n",
        "\n",
        "    # Cargamos el audio\n",
        "    sound_wave, sample_rate = librosa.load(path = file, res_type= 'kaiser_fast')\n",
        "\n",
        "    # Obtenemos sus mfcc's\n",
        "    feature = librosa.feature.mfcc(y = sound_wave, sr = sample_rate, n_mfcc = 40)\n",
        "\n",
        "    # Retornamos los mfcc's del audio\n",
        "    return feature\n",
        "\n",
        "# Hacemos una lista vacía para guardar los mfcc de las canciones\n",
        "extracted = []\n",
        "\n",
        "# Hacemos otra para los features no escalados\n",
        "extracted_cnn = []\n",
        "\n",
        "# Iteramos sobre cada fila del csv\n",
        "for index_num, row in tqdm(meta_data.iterrows()):\n",
        "\n",
        "    # Obtenemos el path del audio\n",
        "    file_name = os.path.join(os.path.abspath(path), 'fold' + str(row[\"fold\"]) + '/', str(row['slice_file_name'])) \n",
        "\n",
        "    # Obtenemos la clase\n",
        "    final_class_labels = row['class']  \n",
        "\n",
        "    # Usamos la función definida arriba para calcular sus mfcc's\n",
        "    data = features_extract(file_name)\n",
        "\n",
        "    # Calculamos la media de cada fila de los mfcc\n",
        "    scaled_feature = np.mean(data.T, axis = 0)    \n",
        "\n",
        "    # Guardamos el audio pre-procesado en mfcc's y su clase en una lista \n",
        "    extracted.append([scaled_feature, final_class_labels])\n",
        "\n",
        "    # Cambiamos las dimensiones del audio para la parte de CNN\n",
        "    X_ = cv2.resize(data, (40, 174), interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "    # Guardamos el audio cambiado de tamaño en una lista\n",
        "    extracted_cnn.append(X_)\n",
        "\n",
        "# Creamos un dataframe con los predictores y la variable respuesta\n",
        "datos = pd.DataFrame(extracted, columns = [\"features\", \"response\"])\n",
        "\n",
        "# Definimos los predictores\n",
        "X = np.array(datos[\"features\"].tolist())\n",
        "\n",
        "# Definimos la variable respuesta\n",
        "y = np.array(datos[\"response\"].tolist())\n",
        "\n",
        "# Definimos el x para la red neuronal convolucional\n",
        "X_cnn = np.array(extracted_cnn)[..., np.newaxis]\n",
        "\n",
        "# Lista con las clases en orden\n",
        "clases = [\"Air Conditioner\", \"Car Horn\", \"Children Playing\", \"Dog Bark\", \"Drilling\", \"Engine Idling\", \"Gun Shot\", \"Jackhammer\", \"Siren\", \"Street Music\"]"
      ],
      "metadata": {
        "id": "XIbzyux_QItP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 1: Comprendientdo los datos (0.2 pts.)\n"
      ],
      "metadata": {
        "id": "fAiSf6OmxeNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Qué son y para qué sirven los MFCC's?\n"
      ],
      "metadata": {
        "id": "mkdUclCqlvMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Si tuvieramos pocos audios para entrenar un modelo ¿Qué técnicas porías usar para enriquecer el set de datos?\n"
      ],
      "metadata": {
        "id": "Wec87HJyltSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 2: Estructura de una red neuronal densa (0.5 pts.)"
      ],
      "metadata": {
        "id": "GIFAGsG70LqX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explica, en términos generales, en qué consiste una red neuronal densa"
      ],
      "metadata": {
        "id": "bPoQ1bOpgYn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Explica qué es una función de activación, y comenta sobre qué propiedades debe cumplir dicha función para poder ser utilizada en una red neuronal. Menciona un ejemplo en particular de función de activación, y fundamenta por qué podría ser utilizada para construir una red neuronal."
      ],
      "metadata": {
        "id": "xE4ON8xEgnSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Investiga sobre el problema de _vanishing gradient_ en el entreamiento de redes neuronales, y cómo la función de activación ReLU proporciona ventajas sobre otras funciones de activación ante este problema."
      ],
      "metadata": {
        "id": "sqCzeIqLyxqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Investiga en qué consiste una capa _softmax_, especificando qué hace y cuál su utilidad en los problemas de clasificación entre varias categorías. "
      ],
      "metadata": {
        "id": "Zp33nyOPzD89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Investiga sobre el optimizador Adam. Explica cómo funciona y qué lo diferencia de SGD (Stochastic Gradient Descent) ¿Qué beneficios tiene y por qué podría ser de utilidad en este contexto?."
      ],
      "metadata": {
        "id": "-MY03a7RzV2q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JKcjq05yNbN"
      },
      "source": [
        "## Actividad 3: Red Neuronal Densa (0.8 pts.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Implementa una red neuronal densa multicapa. Esta debe ser capaz de recibir el set de datos con los MFCC's y entregar un output de 10 dimensiones."
      ],
      "metadata": {
        "id": "7-nEUVMuvXHV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmGQ5wevS2M6"
      },
      "outputs": [],
      "source": [
        "# Separamos en entrenamiento, testeo y validación.\n",
        "# Definimos las proporciones de cada base\n",
        "\n",
        "train_prop = # proporción de entrenamiento\n",
        "test_prop = # proporción de testeo\n",
        "val_prop = # proporción de validación\n",
        "\n",
        "# Separamos nuestras variables en entrenamiento y testeo\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size = test_prop, \n",
        "    random_state = n_alumno\n",
        "    )\n",
        "\n",
        "# Ahora con la de entrenamiento hacemos la de validación\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    test_size = val_prop / (train_prop + test_prop), \n",
        "    random_state = n_alumno\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Grafica cómo varía el accuracy y la función de pérdida con las épocas para los conjuntos de entrenamiento y validación, e interpreta lo que ves.\n"
      ],
      "metadata": {
        "id": "jT7-OrJBzzkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Evalua el accuracy en el set de test. Comenta los resultados brevemente."
      ],
      "metadata": {
        "id": "1-bPstx3z1Pk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2sF5ZKjzI4x"
      },
      "source": [
        "## Actividad 4: Introducción a las Redes Neuronales Convolucionales (0.3 pts.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Lee el siguiente artículo: https://www.ibm.com/cloud/learn/convolutional-neural-networks?utm_medium=OSocial&utm_source=Youtube&utm_content=WAIWW&utm_id=YTDescription-101-What-are-CNNs-LH-CNNs-Guide y explica brevemente en qué consisten las redes neuronales convolucionales (CNN). En tu respuesta, explica la función de los siguientes componenetes de una CNN:\n",
        "  - Convolutional layer\n",
        "  - Pooling layer\n",
        "  - Fully connected layer "
      ],
      "metadata": {
        "id": "_e3umfc-03vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Cuales ventajas tiene una CNN con respecto a las redes neuronales convencionales al trabajar con audio?"
      ],
      "metadata": {
        "id": "VUDhoL9kh8ek"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkR3m8xCyZQg"
      },
      "source": [
        "## Actividad 5: Creando una CNN clasificadora (0.8 pts.)\n",
        "\n",
        "Implementa una red neuronal convolucional para predecir las categorías de los sonidos disponibles. Grafica una matriz de confusión para las categorías predichas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHCIaJUbS2NC"
      },
      "outputs": [],
      "source": [
        "# Separamos en entrenamiento, testeo y validación.\n",
        "\n",
        "# Definimos las proporciones de cada base para la cnn\n",
        "train_prop = # proporción entrenamiento\n",
        "test_prop = # proporción testeo\n",
        "val_prop = # proporción validación\n",
        "\n",
        "# Separamos nuestras variables en entrenamiento y testeo\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_cnn, \n",
        "    y, \n",
        "    test_size = test_prop, \n",
        "    random_state = n_alumno\n",
        "    )\n",
        "\n",
        "# Ahora con la de entrenamiento hacemos la de validación\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    test_size = val_prop / (train_prop + test_prop), \n",
        "    random_state = n_alumno\n",
        "    )\n",
        "\n",
        "# Se definen las dimensiones de entrada a la red neuronal convolucional\n",
        "input_shape_cnn = (X_train_cnn.shape[1], X_train_cnn.shape[2], X_train_cnn.shape[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 6: Comparación de modelos (0.2 pts.)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uNkmWBTi5dxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Cuales son las clases que más se confunden en cada una de las redes neuronales? ¿Por qué crees que ocurre?"
      ],
      "metadata": {
        "id": "kEQ8f0Q0rVyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ¿Cuáles clases son las que peor predicen los modelos? ¿A qué podría deberse esto?"
      ],
      "metadata": {
        "id": "E78uynh1rfcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 7: Probando la CNN (0.2 pts.)"
      ],
      "metadata": {
        "id": "LVDCRPnTnbXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mostrar el nombre de la clase predicha para este audio y mostrar el audio"
      ],
      "metadata": {
        "id": "J7wxEbtAnrp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Si la clase predicha no coincide en el sonido del audio, explicar a qué podría deberse ¿Hay ruido de fondo? ¿El sonido se parece a otra clase?"
      ],
      "metadata": {
        "id": "Z0Wpj0tPr5eW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QH96p-HOvaaX"
      },
      "outputs": [],
      "source": [
        "# Función mencionada en el enunciado que recibe el path a cierto audio .wav\n",
        "def transform(path):\n",
        "\n",
        "    # Utiliza la función entregada más arriba para obtener los MFCC's del audio\n",
        "    audio = features_extract(path)\n",
        "\n",
        "    # Convierte a dimensiones apropiadas\n",
        "    X_ = cv2.resize(audio, (40, 174), interpolation = cv2.INTER_LINEAR)\n",
        "\n",
        "    # Se agrega una dimensión\n",
        "    X = X_[..., np.newaxis].reshape(1, 174, 40, 1)\n",
        "\n",
        "    # Retorna el audio transformado, listo para que el modelo prediga su clase\n",
        "    return X"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "1a0efc7ed7210c8daa9aadd584bbae766f571d407ba1506112b0e572af6a4d67"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}